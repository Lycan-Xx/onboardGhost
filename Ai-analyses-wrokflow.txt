OnboardGhost Analysis Workflow Explanation
When a user submits a GitHub repository URL, OnboardGhost initiates a comprehensive multi-stage analysis workflow designed to extract every piece of information a new developer would need to get started. The process begins by cloning the repository through the GitHub API and immediately scanning for critical configuration files—we parse package.json, requirements.txt, Gemfile, or equivalent dependency manifests to identify the tech stack, detect the primary framework (React, Django, Rails, FastAPI, etc.), and extract version requirements that might cause compatibility issues. Simultaneously, we analyze the file structure to map out important directories like /src, /app, /migrations, and /docs, while locating essential configuration files such as .env.example, docker-compose.yml, and database schema definitions. The README and any CONTRIBUTING.md files are parsed using Gemini AI to extract installation instructions, understand the project's purpose (what problem it solves and how it works), and identify setup prerequisites like required Node.js versions, database types (PostgreSQL, MongoDB, MySQL), environment variables that need configuration, and external service dependencies (Stripe, AWS, SendGrid). We also scan GitHub Issues for common setup problems, check for hardcoded secrets or security vulnerabilities, and assess documentation quality to determine how much hand-holding the onboarding roadmap needs to provide.
All of this extracted intelligence—tech stack details, file paths, setup instructions, known gotchas, dependency relationships, and project purpose—is then fed into two parallel outputs: first, Gemini generates a structured 3-day onboarding roadmap with prioritized tasks ordered by dependency chains (you can't run migrations before installing the database), complete with time estimates, difficulty ratings, code snippets, and contextual tips; second, every code file is chunked into semantic segments, converted into embeddings using HuggingFace's sentence transformers, and stored in Pinecone's vector database alongside rich metadata (file paths, function names, related concepts, common issues). This creates a searchable knowledge base that powers the Ghost Mentor chatbot—when users ask questions like "How does authentication work?" or "Where do I configure the database?", the system performs semantic search to retrieve the 3-5 most relevant code chunks and file references, injects them as context into a Gemini prompt, and generates accurate, codebase-specific answers with file paths and line numbers, effectively giving every user their own personal senior developer who has already read and understood the entire repository.